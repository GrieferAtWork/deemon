/* Copyright (c) 2018-2026 Griefer@Work                                       *
 *                                                                            *
 * This software is provided 'as-is', without any express or implied          *
 * warranty. In no event will the authors be held liable for any damages      *
 * arising from the use of this software.                                     *
 *                                                                            *
 * Permission is granted to anyone to use this software for any purpose,      *
 * including commercial applications, and to alter it and redistribute it     *
 * freely, subject to the following restrictions:                             *
 *                                                                            *
 * 1. The origin of this software must not be misrepresented; you must not    *
 *    claim that you wrote the original software. If you use this software    *
 *    in a product, an acknowledgement (see the following) in the product     *
 *    documentation is required:                                              *
 *    Portions Copyright (c) 2018-2026 Griefer@Work                           *
 * 2. Altered source versions must be plainly marked as such, and must not be *
 *    misrepresented as being the original software.                          *
 * 3. This notice may not be removed or altered from any source distribution. *
 */

/*
 * ============== Documentation for fixincludes annotations ==============
 *
 * - Source files are separated into 2 categories:
 *   - Headers
 *   - Sources
 * - Headers define "exports" using various annotations
 * - Sources (as well as headers) will automatically #include the relevant headers
 * - All annotations are written as "//!foo" or "/ *!foo* /" (without the whitespace after "/")
 * - Only instrumented headers are automatically added/removed from source files.
 *   Headers without exports are always kept as-is!
 * - wildcard exports line-based export annotations always work on a pool of symbols
 *   defined by the associated header file. This pool consists of:
 *   - All C macro definitions (#define foo)
 *   - A best-effort scan of what are probably "symbol" names:
 *     >> int symbol(void);
 *     >> int symbol;
 *     >> int (symbol);
 *     >> int (symbol)(void);
 *     >> int (CC symbol)(void);
 *     >> int CC symbol(void);
 *     >> struct symbol;
 *     >> struct symbol { ... };
 *     None of these match when inside of a {...}-block (iow: when inside of an inline function)
 *
 *
 * ======================== Available annotations ========================
 *
 * >> //!export symbol
 * >> //!export wildcard*pattern
 * >> //!export -not_this_one
 * >> //!export -not_these_*_ones
 * >> #define foo 42           //!export
 * >> extern int bar;          //!export
 * >> extern int baz(void);    //!export
 * >> extern int not_me(void); //!export-
 * >> #ifdef GUARD_SOME_OTHER_HEADER_H
 * >> #define COMBINED_SYMBOL 42 //!export(include("<some/other/header.h>"))
 * >> #endif
 *    Specify symbols exported by the header. Source files that make use
 *    of symbols named by this mechanism will automatically receive the
 *    necessary #include for the header(s) that exports the symbol. When
 *    a symbol requires multiple headers, all required headers will be
 *    included by the relevant source file.
 *
 * >> //!fixincludes no_include_comments
 *    Disable comments describing the reason when this header is #include'ed
 *    Useful for headers that are included pretty much always, or define so
 *    many symbols that an include comment wouldn't be readable.
 *
 * >> //!fixincludes ignore_unnecessary_include
 *    Always retain #include-s to this header, even if they appear to be
 *    unnecessary.
 *
 * >> //!fixincludes discourage_include
 *    For use when another header //!always includes this one: try not to
 *    automatically #include this header, but instead include another header
 *    that //!always includes this one.
 *
 * >> //!fixincludes regex group "__INT(8|16|32|64)_TYPE__" "__INTn_TYPE__" 4
 * >> //!fixincludes regex export "__INT(8|16|32|64)_TYPE__" "__INTn_TYPE__" 4
 *    Add custom patterns and abbreviations used for building include comments
 *    the syntax here is:
 *    //!fixincludes regex [group|export] "REGEX_PATTERN" "REPLACEMENT" MIN_REGEX_MATCHES
 *
 * >> //!always include <__stdinc.h>
 * >> //!always_includes <__stdinc.h>          // DEPRECATED
 * >> #include <__stdinc.h> //!always
 *    Specify that a header is always #include-ing another header. When this
 *    annotation is used, **all** symbols exported by the specified header
 *    are implicitly inherited into the instrumented header, (preety much) as
 *    though those symbols had always been defined by the instrumented header
 *    This annotation may be combined with "//!fixincludes discourage_include"
 *    being annotated in the included header, to further encourage the header
 *    that always #include's another to be injected when a header is missing.
 *
 *
 * The following annotations are ignored:
 * //!KEEPME
 * //!included_by <__stdinc.h>                 // DEPRECATED
 *
 */

import * from deemon;
import * from errors;
import getClangFormatSpecs, ClangFormatSpecs from .clangformat;
import ThreadPool, Task from threading.pool;
import posix;
import functools;

global Header;

local function printStderr(msg: string) {
	__asm__("" : "+X" (msg));
	File.stderr.write(msg + "\n");
}

class DependentFile {
	this = default;
	@@Filename (relative to caller's @Header)
	public member filename: string | none = none;
	@@Raw #include string that is required (in the form like `stddef.h` for `<stddef.h>`)
	public member include: string | none = none;

	public operator str(): string {
		if (include !is none)
			return f'<{include}>';
		return f'"{filename}"';
	}

	public static ofIncludeString(inc: string): DependentFile {
		if (inc.startswith('"')) {
			assert inc.endswith('"');
			return DependentFile(filename: inc[1:-1]);
		}
		assert inc.startswith('<');
		assert inc.endswith('>');
		return DependentFile(include: inc[1:-1]);
	}

	public property asDummyHeader: Header = {
		get(): Header {
			return Header(
				filename: filename,
				includes: include ? Set.frozen{include} : Set(),
			);
		}
	}
}

local function wildcard2regex(wcard: string): string {
	return wcard
		.replace(r"\", r"\\")
		.replace(r"[", r"\[")
		.replace(r"]", r"\]")
		.replace(r"{", r"\{")
		.replace(r"}", r"\}")
		.replace(r".", r"[.]")
		.replace(r"*", r".*")
		.replace(r"?", r".");
}

local final DEFAULT_MIN_COUNT_FOR_EXPORT_GROUP_REPLACEMENT = 3;

class HeaderExportGroup {
	this = default;
	@@Regex that has to match an export, for that export to be part of this group
	public member regex: string;
	@@Replacement when this export group is matched.
	public member replacement: string;
	@@The min # of exports that must be matched before @replacement is injected
	public member minCountForReplacement: int = DEFAULT_MIN_COUNT_FOR_EXPORT_GROUP_REPLACEMENT;

	public operator str(): string {
		return f"{repr regex} -> {repr replacement} (match >= {minCountForReplacement})";
	}

//	public static fromWildcard(wcard: string): HeaderExportGroup {
//		return HeaderExportGroup(
//			regex: wildcard2regex(wcard),
//			replacement: wcard,
//		);
//	}
}

class Header {
	this = default;

	@@Filename of this header (for forming relative/system include strings)
	public member filename: string | none = none;

	@@Raw #include-string that must be written after `#include ...`
	@@When set to @none, the #include string is determined automatically
	public member includes: Set with string = HashSet();

	@@Disable use-comments for keywords from @exports from this @Header and included by source files
	@@>>/*!fixincludes no_include_comments*/
	public member noIncludeComments: bool = false;

	@@Disable warning in IDE regarding unnecessary #includes
	@@>>/*!fixincludes ignore_unnecessary_include*/
	public member ignoreUnnecessaryInclude: bool = false;

	@@Discourage #include-s to this header (instead: suggest other headers that `/*!always*/` include this one)
	@@>>/*!fixincludes discourage_include*/
	public member discourageInclude: bool = false;

	@@Other files that are always included by this one (as specified by ``)
	@@>>/*!always include <stdio.h>*/
	@@>>#include <stdio.h> /*!always*/
	public member alwaysIncludes: Set with DependentFile = HashSet();

	@@Names of header files that always include this header
	public member alwaysIncludedBy: Set with string = HashSet();

	@@Keywords marked as being exported by this header
	@@NOTE: When this set is empty, includes of this header must **NOT** be removed automatically,
	@@      because that means that this header either serves a special purpose (e.g.: is a multi-
	@@      include / code-generating header), or doesn't define any fixincludes specifications.
	public member exports: Set with string = HashSet();

	@@Sub-set of @exports that are inherited from @alwaysIncludes
	public member exportsFromAlwaysIncludes: Set with string = HashSet();

	@@Keywords group wildcard patterns for simplifying include strings
	@@Groups are sorted by the length of their pattern, with longer
	@@patterns being matched before shorter patterns are
	public member exportGroups: {HeaderExportGroup...} = List();

	@@Mapping for `{keyword: {{extraInclude...}...}}` where "extraInclude"
	@@are the names of sets of additional headers of which at least one
	@@set must be fully included (in addition to this header) in order
	@@for the associated `keyword` to truly be exported.
	@@
	@@Used to implement the `!export(include(...))` directive
	public member exportsAfterExtraIncludes: {string: Set with Set with DependentFile} = Dict();

	public operator str(): string {
		local inc: string | none = shortestInclude;
		if (inc !is none)
			return f"<{inc}>";
		return f'"{filename}"';
	}

	public property shortestInclude: string | none = {
		get(): string | none {
			local result = none;
			for (local inc: includes) {
				if (result is none || #result > #inc)
					result = inc;
			}
			return result;
		}
	}

	@@Simplify a list of used exports from this header, by replacing matching elements with @exportGroups
	function simplifyKeywordUseList(usedKwds: Set with string) {
		for (local exportGroup: exportGroups) {
			local matchedKeywords = usedKwds.filter(e -> e.rematches(exportGroup.regex));
			if (#matchedKeywords >= exportGroup.minCountForReplacement) {
				matchedKeywords = matchedKeywords.frozen;
				usedKwds.removeall(matchedKeywords);
				usedKwds.insert(exportGroup.replacement);
			}
		}
	}

	public dump(): Header {
		print(filename, ":");
		if (includes) {
			print("	includes:");
			for (local inc: includes.sorted())
				print("		- ", inc);
		}
		if (noIncludeComments)
			print("	noIncludeComments");
		if (ignoreUnnecessaryInclude)
			print("	ignoreUnnecessaryInclude");
		if (discourageInclude)
			print("	discourageInclude");
		if (alwaysIncludes) {
			print("	alwaysIncludes:");
			for (local x: alwaysIncludes.map(operator str).sorted())
				print("		- ", x);
		}
		if (exports) {
			print("	exports:");
			local longestExportLength: int = exports.each.length > ...;
			for (local x: exports.sorted()) {
				print("		- ", x),;
				if (x in exportsFromAlwaysIncludes)
					print(" " * (longestExportLength - #x), " !inherited"),;
				print;
			}
		}
		if (exportGroups) {
			print("	exportGroups:");
			for (local x: exportGroups)
				print("		- ", x);
		}
		if (exportsAfterExtraIncludes) {
			print("	exportsAfterExtraIncludes:");
			for (local x: exportsAfterExtraIncludes.keys.sorted()) {
				local extra: Set with Set with DependentFile = exportsAfterExtraIncludes[x];
				print("		- ", x, ": ", ", ".join((
					for (local includeGroup: extra)
						f'\{ {", ".join(includeGroup.map(e -> str e))} \}'
				).sorted()));
			}
		}
		return this;
	}
}

@@Mapping of default headers
local final DEFAULT_HEADERS_BY_INCLUDE: {string: Header} = {
#define DEFAULT_HEADER(inc, ...) inc: Header(includes: Set.frozen{inc}, __VA_ARGS__)
	DEFAULT_HEADER("stdarg.h", exports: Set.frozen {
		"va_list", "va_start", "va_arg", "va_copy", "va_end"
	}),
	DEFAULT_HEADER("stddef.h", exports: Set.frozen {
		"NULL", "size_t", "ptrdiff_t", "offsetof",
		"wchar_t", "max_align_t",
	}),
	DEFAULT_HEADER("stdint.h", exports: Set.frozen {
		"int8_t", "int16_t", "int32_t", "int64_t", "intptr_t", "intmax_t",
		"uint8_t", "uint16_t", "uint32_t", "uint64_t", "uintptr_t", "uintmax_t",
		"INT8_C", "INT16_C", "INT32_C", "INT64_C", "INTMAX_C",
		"UINT8_C", "UINT16_C", "UINT32_C", "UINT64_C", "UINTMAX_C",
		"INT8_MIN", "INT16_MIN", "INT32_MIN", "INT64_MIN", "INTMAX_MIN", "INTPTR_MIN", "PTRDIFF_MIN",
		"INT8_MAX", "INT16_MAX", "INT32_MAX", "INT64_MAX", "INTMAX_MAX", "INTPTR_MAX", "PTRDIFF_MAX",
		"UINT8_MAX", "UINT16_MAX", "UINT32_MAX", "UINT64_MAX", "UINTMAX_MAX", "UINTPTR_MAX", "SIZE_MAX",
		"SIG_ATOMIC_MIN", "WCHAR_MIN", "WINT_MIN",
		"SIG_ATOMIC_MAX", "WCHAR_MAX", "WINT_MAX",
	}, exportGroups: {
		HeaderExportGroup("UINT(8|16|32|64)_MAX", "UINTn_MAX", 4),
		HeaderExportGroup("INT(8|16|32|64)_MAX", "INTn_MAX", 4),
		HeaderExportGroup("INT(8|16|32|64)_MIN", "INTn_MIN", 4),
		HeaderExportGroup("UINT(8|16|32|64)_C", "UINTn_C", 4),
		HeaderExportGroup("INT(8|16|32|64)_C", "INTn_C", 4),
		HeaderExportGroup("uint(8|16|32|64)_t", "uintN_t", 4),
		HeaderExportGroup("int(8|16|32|64)_t", "intN_t", 4),
	}),
	DEFAULT_HEADER("stdbool.h", exports: Set.frozen { "bool", "true", "false" }),
#undef DEFAULT_HEADER
}.frozen;


class SrcIncludeInfo {
	this = default;
	public final member include: string;
	public member includeStringOffset: int;
	public member includeStringEndOffset: int;
	public member commentStartOffset: int | none;
	public member commentEndOffset: int | none;
	public member comment: Bytes | string | none;

	@@Is this #include an instance of `/*!fixincludes fake_include ...*/`?
	public member fake: bool = false;

	public property asDependentFile: DependentFile = {
		get(): DependentFile {
			return DependentFile.ofIncludeString(include);
		}
	}

	public patchOffsets(deltaStart: int, deltaOffset: int) {
		if (includeStringOffset >= deltaStart)
			includeStringOffset += deltaOffset;
		if (includeStringEndOffset >= deltaStart)
			includeStringEndOffset += deltaOffset;
		if (commentStartOffset !is none &&
		    commentStartOffset >= deltaStart)
			commentStartOffset += deltaOffset;
		if (commentEndOffset !is none &&
		    commentEndOffset >= deltaStart)
			commentEndOffset += deltaOffset;
	}
};


local class HeaderParser {
	this = default;

	public member filename: string;
	public member header: Header;
	public member data: Bytes;
	public member pos: int = 0;
	public member end: int;
	public member allPotentiallyExportedKeywords: {string...} = HashSet();
	public member exportRegexes: {string...} = HashSet();
	public member exportRegexesAfterExtraIncludes: {string: Set with Set with DependentFile} = Dict();
	public member notExportedKeywords: {string...} = HashSet();
	public member notExportedWildcards: {string...} = HashSet();
	public member hasCustomRegexGroups: bool = false;
	public member keepDefaultRegexGroups: bool = false;

	public member lastExport: string | none = none;
	public member lastExportPos: int = 0;
	public member lastIncludeString: Bytes | none = none;
	public member lastIncludeStringPos: int = 0;

	/* The following stuff is only used when parsing source files */
	public member currentNoFormatRegionStart: int | none = none;
	public member noFormatRegions: {(int, int)...} | none = none;
	@@All keywords that potentially appear somewhere within the file
	public member allKeywords: {string...} | none = none;
	public member allIncludes: {string: SrcIncludeInfo} | none = none;


	public lc(at: int): (int, int) {
		local sol = data.rfind("\n", 0, at) + 1;
		local lno = data.count("\n", 0, sol) + 1;
		return (lno, 1 + at - sol);
	}

	public warn(at: int, msg: string): string {
		local d = lc(at);
		local text = f"{filename}({d[0]}, {d[1]}) : {msg}";
		printStderr(text);
		return text;
	}

	public err(at: int, msg: string) {
		throw Error(warn(at, msg));
	}

	public addPotentiallyExportedKeyword(kwd: string, pos: int) {
		allPotentiallyExportedKeywords.insert(kwd);
		lastExport = kwd;
		lastExportPos = pos;
	}

	public parseIncludeString(): Bytes {
		while (pos < end && data.isspacexlf(pos))
			++pos;
		local includeStringStart: int = pos;
		local includeStringEnd: int;
		if (data.startswith('"', pos, end)) {
			includeStringEnd = data.find('"', pos + 1, end);
		} else if (data.startswith('<', pos, end)) {
			includeStringEnd = data.find('>', pos + 1, end);
		} else {
			err(includeStringStart, "Expected '\"' or '<' after '#include'");
		}
		if (includeStringEnd < 0)
			err(includeStringStart, "Unterminated #include string");
		++includeStringEnd;
		pos = includeStringEnd;
		return data[includeStringStart:includeStringEnd];
	}

	@@Parse and return the next token (yield @"/*" or @"//" for comment start tokens)
	public nextRawNoComment(extraSymbolChars: string = ""): string {
		for (;;) {
			if (pos >= end)
				return "";
			if (!data.isspace(pos))
				break;
			++pos;
		}
		for (local prefix: { "/*", "//" }) {
			if (data.startswith(prefix, pos, end)) {
				pos += #prefix;
				return prefix;
			}
		}
		local result = string.chr(data[pos]);
		if (data.issymstrt(pos) || data.isdigit(pos) || result in extraSymbolChars) {
			local kwdStart = pos;
			do {
				++pos;
			} while (pos < end && (data.issymcont(pos) || (string.chr(data[pos]) in extraSymbolChars)));
			local keyword = data[kwdStart:pos].decode("utf-8");
			if (allKeywords !is none && keyword.issymbol())
				allKeywords.insert(keyword);
			return keyword;
		}
		++pos;
		switch (result) {

		case "'":
		case '"': {
			local stop = result.ord();
			local stringStart = pos;
			local stringEnd = stringStart;
			while (stringEnd < end) {
				local ch = data[stringEnd];
				if (ch == stop)
					break;
				if (ch == '\\'.ord())
					++stringEnd;
				++stringEnd;
			}
			pos = stringEnd + 1;
			/* Normalize to double-quote to simplify processing by caller */
			return f'"{data[stringStart:stringEnd].decode("utf-8")}"';
		}	break;

		}
		return result;
	}

	private findEol(pos: int): int {
		local eol = data.find("\n", pos, end);
		while (eol >= 0) {
			local before = data[eol - 1];
			if ((before == '\\'.ord()) ||
				(before == '\r'.ord() && data[eol - 2] == '\\'.ord())) {
				eol = data.find("\n", eol + 1, end);
			} else {
				break;
			}
		}
		if (eol < 0)
			eol = end;
		return eol;
	}

	private findEolWithBlockComments(pos: int): int {
again:
		local eol = findEol(pos);
		local blockCommentStart = data.find("/*", pos, eol);
		if (blockCommentStart >= pos) {
			local blockCommentEnd = data.find("*/", blockCommentStart + 2, end);
			if (blockCommentEnd > eol) {
				pos = blockCommentEnd + 2;
				goto again;
			}
		}
		return eol;
	}

	public nextExportKeyword(): string {
		return nextRawNoComment("-*?");
	}

	public nextString(opt: bool = false): string | none {
		local stringStart = pos;
		local result = nextRawNoComment();
		if (opt && !result)
			return none;
		if (!result.startswith('"') || !result.endswith('"'))
			err(stringStart, f"Expected string literal, but got {repr result}");
		try {
			return result.decode("c-escape");
		} catch (Error as e) {
			err(stringStart, f"Failed to parse string {repr result}: {e.message}");
		}
	}

	public nextInt(opt: bool = false): int | none {
		local intStart = pos;
		local result = nextRawNoComment();
		if (opt && !result)
			return none;
		try {
			return int(result);
		} catch (Error as e) {
			err(intStart, f"Failed to parse integer {repr result}: {e.message}");
		}
	}

	public parseComment() {
		if (!data.startswith("!", pos, end)) {
			local tok = nextRawNoComment("-");
			if (tok == "clang-format") {
				tok = nextRawNoComment("-");
				if (tok == "off") {
					currentNoFormatRegionStart = pos;
				} else if (tok == "on" && currentNoFormatRegionStart !is none) {
					noFormatRegions.append((currentNoFormatRegionStart, pos));
					currentNoFormatRegionStart = none;
				}
			}
			return;
		}
		local directiveStart = pos;
		++pos;
		local tok = nextRawNoComment();
		switch (tok) {

		case "export": {
			tok = nextExportKeyword();
again_export_directive:
			local isRegex: bool;
			local keywordOrRegex: string;
			local regexReplacement: string;
			if (!tok) {
				if (!lastExport)
					err(directiveStart, f"Got /*!export*/ directive without preceding keyword");
				isRegex = false;
				keywordOrRegex = lastExport;
			} else if (tok == "-") {
				if (!lastExport)
					err(directiveStart, f"Got /*!export-*/ directive without preceding keyword");
				isRegex = false;
				keywordOrRegex = "-" + lastExport;
				tok = nextExportKeyword();
			} else if ("*" in tok || "?" in tok) {
				isRegex = true;
				regexReplacement = tok;
				keywordOrRegex = wildcard2regex(tok);
				tok = nextExportKeyword();
			} else if (tok.issymbol() || (tok.startswith("-") && tok[1:].issymbol())) {
				isRegex = false;
				keywordOrRegex = tok;
				tok = nextExportKeyword();
			} else if (tok == "(") {
				if (!lastExport)
					err(directiveStart, f"Got /*!export(...)*/ directive without preceding keyword");
				isRegex = false;
				keywordOrRegex = lastExport;
			} else {
				err(directiveStart, f"Unexpected token after '/*!export': {repr tok}");
			}

			/* Deal with negative exports */
			if (keywordOrRegex.startswith("-")) {
				(isRegex ? notExportedWildcards : notExportedKeywords)
					.insert(keywordOrRegex[1:]);
				if (tok)
					goto again_export_directive;
				break;
			}

			/* Remember export */
			if (isRegex) {
				exportRegexes.insert(keywordOrRegex);
				if (keywordOrRegex != ".*" && (!hasCustomRegexGroups || keepDefaultRegexGroups) &&
				    !header.exportGroups.any(e -> e.regex == keywordOrRegex)) {
					header.exportGroups.append(HeaderExportGroup(
						regex:       keywordOrRegex,
						replacement: regexReplacement,
					));
				}
			} else {
				header.exports.insert(keywordOrRegex);
			}

			/* Process extra export parameters */
			if (tok == "(") {
				tok = nextRawNoComment();
				for (;;) {
					if (tok == "include") {
						tok = nextRawNoComment();
						if (tok != "(") {
							err(directiveStart, f"Expected '(' after '/*!export {
								keywordOrRegex}(include', but got {repr tok}");
						}
						local reqIncludes: {DependentFile...} = HashSet();
						for (;;) {
							local incString = parseIncludeString().decode("utf-8");
							reqIncludes.insert(DependentFile.ofIncludeString(incString));
							tok = nextRawNoComment();
							if (tok != ",")
								break;
						}
						if (tok != ")") {
							err(directiveStart, f"Expected ')' after '/*!export {
									keywordOrRegex}(include(...', but got {repr tok}");
						}
						(isRegex ? exportRegexesAfterExtraIncludes
						            : header.exportsAfterExtraIncludes
						).setdefault(keywordOrRegex, HashSet()).insert(reqIncludes);
						tok = nextRawNoComment();
					} else {
						err(directiveStart, f"Unexpected parameter {
							repr tok} '/*!export {keywordOrRegex}('");
					}
					if (tok != ",")
						break;
					tok = nextRawNoComment();
					if (tok == ")")
						break;
				}
				if (tok != ")") {
					err(directiveStart, f"Expected ')' after '/*!export {
						keywordOrRegex}(include(...', but got {repr tok}");
				}
				tok = nextExportKeyword();
			}
			if (tok)
				goto again_export_directive;
		}	break;

		case "fixincludes": {
			tok = nextRawNoComment();
			switch (tok) {
			case "no_include_comments":
				header.noIncludeComments = true;
				break;
			case "ignore_unnecessary_include":
				header.ignoreUnnecessaryInclude = true;
				break;
			case "discourage_include":
				header.discourageInclude = true;
				break;
			case "regex": {
				local regexCommand = nextRawNoComment();
				switch (regexCommand) {
				case "keep_default_groups":
					keepDefaultRegexGroups = true;
					break;
				case "group":
					/* //!fixincludes regex group "__INT(8|16|32|64)_TYPE__" "__INTn_TYPE__" 4
					 *
					 * Define custom "header.exportGroups". Also causes all automatically generated
					 * export groups (e.g. `//!export __INT*_TYPE__`) to be deleted, and any further
					 * wildcard-export directives within the same file no longer create automatic
					 * groups. */
				case "export": {
					/* //!fixincludes regex export "__INT(8|16|32|64)_TYPE__" "__INTn_TYPE__" 4
					 *
					 * Same as "fixincludes regex group", but also causes all symbols matching the
					 * specified regex to be added to "header.exports" at the end. This can be done
					 * by simply adding the regex string to "this.exportRegexes". */
					local regex: string = nextString();
					local replacement: string = nextString();
					local minCount: int = nextInt(opt: true)
						?? DEFAULT_MIN_COUNT_FOR_EXPORT_GROUP_REPLACEMENT;
					if (!hasCustomRegexGroups) {
						if (!keepDefaultRegexGroups)
							header.exportGroups.clear();
						hasCustomRegexGroups = true;
					}
					header.exportGroups.append(HeaderExportGroup(
							regex:                  regex,
							replacement:            replacement,
							minCountForReplacement: minCount,
					));
					if (regexCommand == "export")
						exportRegexes.insert(regex);
				}	break;

				default:
					err(directiveStart, f"Unsupported regex command: '/*!fixincludes regex {regexCommand}...'");
					break;
				}
			}	break;

			case "fake_include": {
				/* Used to inject a fake #include directive.
				 * For when you intentionally want to have a missing include */
				lastIncludeStringPos = pos;
				lastIncludeString = parseIncludeString();
				if (allIncludes !is none)
					addAllIncludesEntry(fake: true);
				tok = nextRawNoComment();
				if (tok != "//") {
					err(directiveStart, f"Expected '//' after '/*!fixincludes fake_include {
						lastIncludeString}', but got '{tok}'");
				}
				pos = end; /* Skip remainder (which is the generated include comment) */
			}	break;

			default:
				err(directiveStart, f"Unsupported command: '/*!fixincludes {tok}...'");
				break;
			}
			tok = nextRawNoComment();
			if (tok)
				err(directiveStart, f"Encountered garbage after '/*!fixincludes...*/': '{tok}'");
		}	break;

		case "always": {
			tok = nextRawNoComment();
			local includeString: Bytes;
			if (!tok) {
				includeString = lastIncludeString;
				if (!includeString)
					err(directiveStart, f"Got '/*!always*/' directive without preceding #include");
				local sol = data.rfind("\n", 0, pos) + 1;
				if (lastIncludeStringPos < sol) {
					err(directiveStart,
						f"Last include string {repr includeString} is on "
						f"different line than '/*!always*/' directive");
				}
			} else if (tok == "include") {
				includeString = parseIncludeString();
			} else {
				err(directiveStart, f"Unexpected token after '/*!always': {repr tok}");
			}
			local dep = DependentFile.ofIncludeString(includeString.decode("utf-8"));
			header.alwaysIncludes.insert(dep);
			tok = nextRawNoComment();
			if (tok)
				err(directiveStart, f"Encountered garbage after '/*!export ...*/': {repr tok}");
		}	break;

		case "KEEPME": {
			/* Marker unrelated to fixincludes headers, used
			 * to annotate lines that should not be removed */
			local sol = data.rfind("\n", 0, pos) + 1;
			noFormatRegions.append((sol, end));
		}	break;

		case "always_includes": {
			local includeString = parseIncludeString();
			local dep = DependentFile.ofIncludeString(includeString.decode("utf-8"));
			header.alwaysIncludes.insert(dep);
			tok = nextRawNoComment();
			if (tok)
				err(directiveStart, f"Encountered garbage after '/*!always_includes ...*/': {repr tok}");
		}	break;

		case "included_by":
			/* Deprecated (related to legacy KOS-style .editorconfig generator) */
			break;

		default:
			warn(directiveStart, f"Unknown fixincludes directive {repr tok}");
			break;
		}
	}

	@@Parse and return the next token (handles comments)
	public nextRaw(): string {
again:
		local result = nextRawNoComment();
		switch (result) {

		case "/*": {
			local commentEnd = data.find("*/", pos, end);
			if (commentEnd < 0)
				commentEnd = end;
			local oldEnd = end;
			local oldAllKeywords = allKeywords;
			allKeywords = none;
			end = commentEnd;
			parseComment();
			allKeywords = oldAllKeywords;
			end = oldEnd;
			pos = commentEnd + 2;
			goto again;
		}	break;

		case "//": {
			local eol = findEol(pos);
			local oldEnd = end;
			local oldAllKeywords = allKeywords;
			allKeywords = none;
			end = eol;
			parseComment();
			allKeywords = oldAllKeywords;
			end = oldEnd;
			pos = eol + 1;
			goto again;
		}	break;

		default: break;
		}
		return result;
	}

	private addAllIncludesEntry(fake: bool = false) {
		local includeString: string = lastIncludeString.decode("utf-8");
		if (includeString !in allIncludes) {
			local includeStringEndOffset: int = pos;
			local i = pos;
			local len = end;

			/* Check for include comments */
			for (;;) {
				while (i < len && data.isspacexlf(i))
					++i;
				if (!data.startswith("/*!", i, len))
					break;
				/* fixincludes directives are processed later */
				local directiveEnd = data.find("*/", i + 3, len);
				if (directiveEnd < 0)
					directiveEnd = len;
				i = directiveEnd;
			}

			local commentStartOffset: int | none = none;
			local commentEndOffset: int | none = none;
			if (data.startswith("/*", i, len)) {
				i += 2;
				commentStartOffset = i;
				i = data.find("*/", i, len);
				if (i < 0)
					i = len;
				commentEndOffset = i;
				i += 2;
			} else if (data.startswith("//!", i, len)) {
				/* There is no include comment... */
			} else if (data.startswith("//", i, len)) {
				i += 2;
				commentStartOffset = i;
				i = data.find("\n", i, len);
				if (i < 0)
					i = len;
				if (i > commentStartOffset && data[i - 1] == '\r'.ord())
					--i;
				commentEndOffset = i;
				i += 1;
			}

			local comment: Bytes | none = none;
			if (commentStartOffset !is none) {
				while (commentStartOffset < commentEndOffset && data.isspace(commentStartOffset))
					++commentStartOffset;
				while (commentEndOffset > commentStartOffset && data.isspace(commentEndOffset - 1))
					--commentEndOffset;
				comment = data[commentStartOffset:commentEndOffset];
			}
			allIncludes[includeString] = SrcIncludeInfo(
				include:                includeString,
				includeStringOffset:    lastIncludeStringPos,
				includeStringEndOffset: includeStringEndOffset,
				commentStartOffset:     commentStartOffset,
				commentEndOffset:       commentEndOffset,
				comment:                comment,
				fake:                   fake,
			);
		}
	}

	@@Place @pos after the keyword of the next preprocessor directive, and return the directive
	private seekNextPPBlockDirective(): string {
again:
		local result = nextRaw();
		if (result == "#") {
			local sol = data.rfind("\n", 0, pos) + 1;
			if (data.isspace(sol, pos - 1)) {
				while (pos < end && data.isspacexlf(pos))
					++pos;
				if (pos < end && data.issymstrt(pos)) {
					local directiveStart = pos;
					do {
						++pos;
					} while (pos < end && data.issymcont(pos));
					return data[directiveStart:pos].decode("utf-8");
				}
			}
			goto again;
		}
		if (!result)
			return result;
		goto again;
	}

	public parseDirective(origEnd: int): int | none {
		local oldAllKeywords = allKeywords;
		allKeywords = none;
		local cmd = nextRaw();
		allKeywords = oldAllKeywords;
		switch (cmd) {

		case "define": {
			local kwdStart = pos;
			local kwd = nextRaw();
			if (!kwd.issymbol())
				err(kwdStart, f"Expected keyword after '#define', but got {repr kwd}");
			addPotentiallyExportedKeyword(kwd, kwdStart);
		}	break;

		case "include":
			lastIncludeStringPos = pos;
			lastIncludeString = parseIncludeString();
			if (allIncludes !is none)
				addAllIncludesEntry();
			break;

		case "if": {
			local exprEnd2 = data.find("/*", pos, end);
			if (exprEnd2 < 0)
				exprEnd2 = end;
			local exprEnd = data.find("//", pos, exprEnd2);
			if (exprEnd < 0)
				exprEnd = exprEnd2;
			while (pos < exprEnd && data.isspace(pos))
				++pos;
			while (exprEnd > pos && data.isspace(exprEnd - 1))
				--exprEnd;
			if (data[pos:exprEnd] == "0") {
				/* "#if 0 ... #endif" -- skip block (parse //!comments, but don't scan for keyword definitions) */
				local recursion = 1;
				local oldAllKeywords = allKeywords;
				allKeywords = none;
				end = origEnd;
				for (;;) {
					local next = seekNextPPBlockDirective();
					if (!next)
						break;
					if (next == "if") {
						++recursion;
					} else if (next in ["else", "elif"] && recursion <= 1) {
						break;
					} else if (next == "endif") {
						if (recursion <= 1)
							break;
						--recursion;
					}
				}
				allKeywords = oldAllKeywords;
				return pos;
			}
		}	break;


		default: break;
		}
		return none;
	}

	@@Parse and return the next token (handles comments + PP directives)
	public next(): string {
again:
		local result = nextRaw();
		if (result == "#") {
			local sol = data.rfind("\n", 0, pos) + 1;
			if (data.isspace(sol, pos - 1)) {
				local eol = findEolWithBlockComments(pos);
				local oldEnd = end;
				end = eol;
				local status: int | none = parseDirective(oldEnd);
				if (status is none) {
					while (nextRaw()); /* Parse additional comments found within... */
					pos = eol + 1;
				} else {
					pos = status;
				}
				end = oldEnd;
				goto again;
			}
		}
		return result;
	}

	@@Returns the last token before the final, closing paren
	private skipParenBlock(open: string): (string, int) {
		local close = {
			"{" : "}",
			"(" : ")",
			"[" : "]",
		}[open];
		local count = 1;
		local result = (open, pos);
		for (;;) {
			local tokPos = pos;
			local tok = next();
			if (tok == open) {
				++count;
				result = (tok, tokPos);
			} else if (tok == close) {
				--count;
				if (count == 0)
					break;
			} else if (!tok) {
				break;
			} else {
				result = (tok, tokPos);
			}
		}
		return result;
	}

	public parseAll(): HeaderParser {
again:
		local tok = next();
again_tok:
		if (!tok)
			return this;

		/* Skip paren-blocks */
		switch (tok) {

		case "{":
		case "[":
skip_paren_block:
			skipParenBlock(tok);
			goto again;

		case "(": {
			local keyword, keywordPos = skipParenBlock(tok)...;
			tok = next();
			if (tok == "(" && keyword.issymbol()) {
				/* This matches the "foo" in: "DECL int NOTHROW(LIBCCALL foo)(void);" */
				addPotentiallyExportedKeyword(keyword, keywordPos);
				do {
					skipParenBlock("(");
					tok = next();
				} while (tok == "(");
			}
			goto again_tok;
		}	break;

		case "struct":
		case "union":
		case "enum": {
			local keywordPos = pos;
			local keyword = next();
			if (keyword.issymbol()) {
				tok = next();
				if (tok == "{") {
					addPotentiallyExportedKeyword(keyword, keywordPos);
					goto skip_paren_block;
				} else if (tok == ";") {
#if 1 /* Incomplete struct shouldn't be considered an export (except
       * when parsing as a source file, in which case it must count
       * as one since it can be used to prevent the necessity of an
       * include) */
					if (allKeywords !is none)
#endif
					{
						addPotentiallyExportedKeyword(keyword, keywordPos);
					}
					goto again;
				}
				goto again_tok;
			}
			tok = keyword;
			goto again_tok;
		}	break;

		default: break;
		}

		if (!tok.issymbol())
			goto again;
		local keyword = tok;
		local keywordPos = pos - #keyword; /* Hacky, but good enough */
		tok = next();
		while (tok == "[") {
			skipParenBlock("[");
			tok = next();
		}

		/* This matches the "foo" in: "DECL int foo;"
		 *
		 * TODO: Find a way so we're able to match "foo" in:
		 * >> int foo __attribute__((aligned(42)));
		 *
		 * Current, we'd actually match "__attribute__" as an export name! */
		if (tok in ";") {
			addPotentiallyExportedKeyword(keyword, keywordPos);
			goto again;
		}

		/* This matches the "foo" in: "DECL int foo();", but not "int" in "DECL int (foo)();" */
		if (tok == "(") {
			do {
				local lastKwdInParen, lastKwdInParenPos = skipParenBlock("(")...;
				tok = next();
				if (tok in ";{") {
					/*     "DECL int foo();"
					 * or: "DECL int foo() { ... }"
					 * or: "DECL int (foo)();"
					 * or: "DECL int (foo)() { ... }"
					 */
					addPotentiallyExportedKeyword(keyword, keywordPos);
					goto again_tok;
				}
				if (!lastKwdInParen.issymbol())
					goto again;
				keyword = lastKwdInParen;
				keywordPos = lastKwdInParenPos;
			} while (tok == "(");
		}
		goto again_tok;
	}

	public finish(): Header {
		local exports: HashSet with string = header.exports;
		/* Add exports that were specified via wildcards */
		if (exportRegexes.remove(".*")) {
			exports.insertall(allPotentiallyExportedKeywords);
		} else {
			for (local kwd: allPotentiallyExportedKeywords) {
				if (exportRegexes.any(kwd.rematches))
					exports.insert(kwd);
			}
		}

		/* Remove symbols that are explicitly NOT exported */
		if (notExportedWildcards) {
			for (local kwd: exports) {
				if (notExportedWildcards.any(kwd.rematches))
					notExportedKeywords.insert(kwd);
			}
		}
		exports.removeall(notExportedKeywords);

		/* Add extra-include-requirements that were specified via wildcards */
		for (local rx, incGroups: exportRegexesAfterExtraIncludes) {
			for (local kwd: allPotentiallyExportedKeywords) {
				if (kwd.rematches(rx)) {
					header.exportsAfterExtraIncludes
						.setdefault(kwd, HashSet())
						.insert(incGroups);
				}
			}
		}
		/* group.regex.length DESC, group.replacement ASC */
		header.exportGroups.sort(e -> (-e.regex.length, e.replacement));
		return header;
	}
}

function loadHeaderWithData(filename: string, data: Bytes): Header {
	return HeaderParser(
		data:     data,
		end:      #data,
		header:   Header(filename: filename),
		filename: filename,
	).parseAll().finish();
}

function loadHeader(filename: string): Header {
	local data: Bytes;
	with (local fp = File.open(filename, "rb"))
		data = fp.read();
	return loadHeaderWithData(filename, data);
}




class SrcIncludeGroup {
	this = default;
	public final member includes: {SrcIncludeInfo...} = [];
	public member groupStartOffset: int;
	public member groupEndOffset: int;

	public patchOffsets(deltaStart: int, deltaOffset: int) {
		if (groupStartOffset >= deltaStart)
			groupStartOffset += deltaOffset;
		if (groupEndOffset >= deltaStart)
			groupEndOffset += deltaOffset;
	}

	public function containsIncludePriority(specs: ClangFormatSpecs, priority: int) {
		for (local include: includes) {
			if (priority == specs.getIncludePriorty(include.include))
				return true;
		}
		return false;
	}

	public function reformat(specs: ClangFormatSpecs): Bytes | none {
		if (!includes)
			return none;
		local regexToPriority: {string: int} = specs.IncludeCategories;
		local includesByPriority: {int: {SrcIncludeInfo...}} = Dict();
		for (local include: includes) {
			local priority = specs.getIncludePriorty(include.include);
			includesByPriority.setdefault(priority, []).append(include);
		}
		if (specs.SortIncludes) {
			for (local none, includes: includesByPriority)
				includes.sort();
		}
		File.Writer result;
		for (local prio: includesByPriority.keys.sorted()) {
			local includes = includesByPriority[prio];
			local maxIncludeStringLength = includes.each.include.length > ...;
			for (local include: includes) {
				local includeString = include.include;
				if (include.fake) {
					result << "/*!fixincludes fake_include " << includeString;
					if (include.comment is none) {
						result << " // */";
					} else {
						result << " " * (maxIncludeStringLength - #includeString);
						result << " // " << include.comment << " */";
					}
				} else {
					result << "#include " << includeString;
					if (include.comment !is none) {
						result << " " * (maxIncludeStringLength - #includeString);
						result << " /* " << include.comment << " */";
					}
				}
				result << "\n";
			}
			result << "\n"; /* Group separator */
		}
		return result.string.encode("utf-8").rstrip(); /* Strip unnecessary, trailing linefeeds */
	}

	public function addInclude(include: string, comment: string) {
		includes.append(SrcIncludeInfo(
			include: include,
			includeStringOffset: -1,
			includeStringEndOffset: -1,
			commentStartOffset: none,
			commentEndOffset: none,
			comment: comment,
		));
	}
}

global FixIncludes;

class FixConfig {
	this = default;

	@@Configure how missing includes should be generated. Possible values:
	@@ - @"shortest": Use either `<foo.h>` or `"foo.h"`, which-ever is shorter.
	@@   When both are equal-sized, prefer `"foo.h"`
	@@ - @"relative": Always use `"foo.h"`, except when impossible
	@@ - @"system": Always use `<foo.h>`, except when impossible
	@@ - @"relativeIfNoUpRefs": Always use `"foo.h"`, but try not to use `"../foo.h"`
	@@ - @"shortestButNoUpRefs": Use the shortest, but always use `<foo.h>` over `"../foo.h"`
	public final member missingIncludeFormat: string = "shortest";
}

class SrcFileInfo {
	this = default;
	public final member filename: string;
	public final member includes: {string: SrcIncludeInfo};
	public final member keywords: {string...};
	public final member noFormatRegions: {(int, int)...};
	public member data: Bytes;
	public member dataChanged: bool = false;

	@@Keywords that (appear to be) provided by the module itself
	public final member selfProvidedKeyword: {string...};

	/* TODO: selfProvidedKeyword: {string...}
	 *
	 * When the file contains a line like:
	 * >> struct Dee_thread_object;  // No need to #include <deemon/thread.h>
	 * >> #define strlen my_strlen   // No need to #include <deemon/system-features.h>
	 *
	 * This should use the same symbol-detection-function as used by "HeaderParser"!
	 *
	 * NOTE: However, if the relevant #include is already present, and all symbols,
	 *       somehow exported by the header are re-defined in this manner locally,
	 *       then the header mustn't be auto-removed. -- There may be a reason why
	 *       the include is present anyways. */

	private member m_clangFormatSpecs: ClangFormatSpecs;
	public property clangFormatSpecs: ClangFormatSpecs = {
		get(): ClangFormatSpecs {
			if (m_clangFormatSpecs !is bound)
				m_clangFormatSpecs = getClangFormatSpecs(posix.headof(filename));
			return m_clangFormatSpecs;
		}
	}

	private function getIncludeLineStart(inc: SrcIncludeInfo): int {
		return data.rfind("\n", 0, inc.includeStringOffset) + 1;
	}
	private function getIncludeLineEnd(inc: SrcIncludeInfo): int {
		local result;
		if (inc.commentEndOffset is none) {
			result = inc.includeStringEndOffset;
		} else {
			result = data.index("*/", inc.commentEndOffset) + 2;
		}
		while (result < #data && data.isspacexlf(result))
			++result;
		return result;
	}

	private member m_includeGroups: {SrcIncludeGroup...};
	public property includeGroups: {SrcIncludeGroup...} = {
		get(): {SrcIncludeGroup...} {
			if (m_includeGroups is bound)
				return m_includeGroups;
			local sortedIncludes: {SrcIncludeInfo...} = includes.values.sorted(e -> e.includeStringOffset);
			local result: {SrcIncludeGroup...} = List();
			local currentGroup = SrcIncludeGroup();
			for (local inc: sortedIncludes) {
				if (!currentGroup.includes) {
insert_first_include:
					currentGroup.includes.append(inc); /* First include of group */
					currentGroup.groupStartOffset = getIncludeLineStart(inc);
					currentGroup.groupEndOffset = getIncludeLineEnd(inc);
				} else {
					local prevIncludeEnd = currentGroup.groupEndOffset;
					local thisIncludeLine = getIncludeLineStart(inc);
					while (prevIncludeEnd < thisIncludeLine && data.isspace(prevIncludeEnd))
						++prevIncludeEnd;
					if (prevIncludeEnd >= thisIncludeLine) {
						/* Same group */
						currentGroup.includes.append(inc);
						currentGroup.groupEndOffset = getIncludeLineEnd(inc);
					} else {
//						printStderr("NEW GROUP:");
//						printStderr(f"	prev: {prevIncludeEnd} {repr lc(prevIncludeEnd)}");
//						printStderr(f"	curr: {thisIncludeLine} {repr lc(thisIncludeLine)}");
//						printStderr(f"	data: {repr data[prevIncludeEnd:thisIncludeLine]}");

						/* New group */
						result.append(currentGroup);
						currentGroup = SrcIncludeGroup();
						goto insert_first_include;
					}
				}
			}
			if (currentGroup.includes)
				result.append(currentGroup);
			m_includeGroups = result;
			return result;
		}
	}

	private function isFormattingDisabledAt(offset: int): bool {
		for (local start, end: noFormatRegions) {
			if (offset >= start && offset < end)
				return true;
		}
		return false;
	}

	private patchOffsets(deltaStart: int, deltaOffset: int) {
		for (local inc: includes.values) {
			inc.patchOffsets(deltaStart, deltaOffset);
		}
		if (m_includeGroups is bound) {
			for (local group: m_includeGroups)
				group.patchOffsets(deltaStart, deltaOffset);
		}
		for (local i: [:#noFormatRegions]) {
			local start, end = noFormatRegions[i]...;
			if (start >= deltaStart)
				start += deltaOffset;
			if (end >= deltaStart)
				end += deltaOffset;
			noFormatRegions[i] = (start, end);
		}
	}

	private overwrite(offset: int, count: int, more: string | Bytes): bool {
		if (count || more) {
			if (more is string)
				more = more.encode("utf-8");
			local oldData = data[offset:offset + count];
			if (oldData != more) {
				data = data[:offset] + more + data[offset+count:];
				dataChanged = true;
				patchOffsets(offset, #more - count);
				return true;
			}
		}
		return false;
	}

	private insert(offset: int, more: string | Bytes) {
		return overwrite(offset, 0, more);
	}

	private delete(offset: int, count: int) {
		return overwrite(offset, count, "");
	}

	private lc(offset: int): (int, int) {
		local sol = data.rfind("\n", 0, offset) + 1;
		local lno = data.count("\n", 0, sol) + 1;
		return (lno, 1 + offset - sol);
	}

	@@Returns sequence {(missingHeader, {usedKeywordFromheader...})...}
	@@@param keywordsFromIncludes Keywords that belong to known includes
	private function getMissingHeadersAndKeywords(
			fixIncludes: FixIncludes,
			keywordsFromIncludes: {string...},
			includedFilenames: {string...},
			includedSystemIncludes: {string...},
	): {(Header, Set with string)...} {
		local missingHeaders: {Header...} = [];
		local missingByFilename: {string: Set with string} = Dict();
		for (local kwd: keywords) {
			if (kwd in keywordsFromIncludes)
				continue; /* From known include... */
			if (kwd in selfProvidedKeyword)
				continue; /* From the file itself (potentially) */
			local missingHeaderCombinations: Set with {Header...} = fixIncludes.getHeaderByExport(kwd);
			if (!missingHeaderCombinations)
				continue;
			for (local combination: missingHeaderCombinations) {
				if (combination.any(e -> e.filename == filename))
					goto next_keyword; /* Symbol is defined by the file we're trying to fix -> ignore */
				if (combination.all(e -> (
					(e.filename in includedFilenames)
				))) {
					goto next_keyword; /* Symbol is defined by the file we're trying to fix -> ignore */
				}
			}

			local usedCombination: {Header...} | none = none;
			local usedCombinationScore: int = 99999999999999;
			for (local combination: missingHeaderCombinations) {
				local combinationFilenames: {string...} = combination.each.filename;
				local stillMissingIncludes = 0;
				for (local hdr: combination) {
					local hdrFilename = hdr.filename;
					if (hdrFilename !in includedFilenames &&
					    hdrFilename !in missingByFilename)
						stillMissingIncludes += 2;
					if (kwd in hdr.exportsFromAlwaysIncludes)
						stillMissingIncludes += 1; /* Discourage this inclusion over the original header */
				}
				local score = stillMissingIncludes + #combination * 4;
				if (usedCombination is none || usedCombinationScore > score) {
					usedCombination = combination;
					usedCombinationScore = score;
				}
			}
			assert usedCombination !is none;
			for (local hdr: usedCombination) {
				local hdrFilename = hdr.filename;
				local importedKeywords: (Set with string) | none = missingByFilename.get(hdrFilename);
				if (importedKeywords is none) {
					missingByFilename[hdrFilename] = importedKeywords = HashSet();
					missingHeaders.append(hdr);
				}
				importedKeywords.insert(kwd);
			}
next_keyword:;
		}
		return (
			for (local hdr: missingHeaders)
				(hdr, missingByFilename[hdr.filename])
		);
	}

	public fix(fixIncludes: FixIncludes, config: FixConfig) {
		local removedIncludes: {string...} = HashSet();
		local keywordsFromIncludes: {string...} = HashSet();
		local includedFilenames: {string...} = HashSet();
		local includedSystemIncludes: {string...} = HashSet();
		for (local inc: includes.values) {
			local dep: DependentFile = inc.asDependentFile;
			local incHdr: Header | none = fixIncludes.getDependentHeader(filename, dep);
			if (incHdr is none) {
				if (dep.filename !is none) {
					local absFilename = dep.filename;
					if (!posix.isabs(absFilename))
						absFilename = posix.abspath(absFilename, posix.headof(inc.include));
					absFilename = posix.resolvepath(absFilename);
					includedFilenames.insert(absFilename);
				}
				if (dep.include !is none)
					includedSystemIncludes.insert(dep.include);
			} else {
				includedFilenames.insert(incHdr.filename);
				local usedKwds = HashSet(
					for (local k: incHdr.exports)
						if (k in this.keywords)
							k
				);
				if (!usedKwds) {
					if (incHdr.exports && !incHdr.ignoreUnnecessaryInclude &&
					    !isFormattingDisabledAt(inc.includeStringOffset)) {
						printStderr(f"{filename}: Removing unnecessary include {inc.include}");
						local sol = getIncludeLineStart(inc);
						local eol = getIncludeLineEnd(inc);
						if (eol < #data && data.islf(eol))
							++eol;
						delete(sol, eol - sol);
						removedIncludes.insert(inc.include);
					}
				} else {
					keywordsFromIncludes.insertall(usedKwds);
					incHdr.simplifyKeywordUseList(usedKwds);
					local correctKwdsComment = ", ".join(usedKwds.sorted(
						functools.predcmp2key(string.vercompare)
					));
					local actualKwdsComment = "";
					if (inc.commentStartOffset !is none) {
						actualKwdsComment = data[
							inc.commentStartOffset:
							inc.commentEndOffset
						].decode("utf-8");
					}
					if (actualKwdsComment != correctKwdsComment &&
					    !isFormattingDisabledAt(inc.commentStartOffset) &&
					    !incHdr.noIncludeComments) {
						printStderr(f"{filename}: Fixing bad comment for {inc.include}: {
							repr actualKwdsComment} -> {repr correctKwdsComment}");
						if (inc.commentStartOffset !is none) {
							overwrite(
								inc.commentStartOffset,
								inc.commentEndOffset - inc.commentStartOffset,
								correctKwdsComment);
						} else {
							local data = f" /* {correctKwdsComment} */".encode("utf-8");
							local index = inc.includeStringEndOffset;
							insert(index, data);
							inc.commentStartOffset = index + 4;
							inc.commentEndOffset = index + #data - 3;
						}
						inc.comment = correctKwdsComment;
					}
				}
			}
		}
		for (local x: removedIncludes)
			del includes[x];

		/* Check for missing includes, insert into groups, and re-format groups */
		local missing = getMissingHeadersAndKeywords(
				fixIncludes: fixIncludes,
				keywordsFromIncludes: keywordsFromIncludes,
				includedFilenames: includedFilenames,
				includedSystemIncludes: includedSystemIncludes,
		);
		local includeGroups = this.includeGroups;
		for (local hdr, keywords: missing) {
			local systemIncludeString: string | none = hdr.shortestInclude;
			if (systemIncludeString !is none)
				systemIncludeString = f"<{systemIncludeString}>";
			local relativeIncludePath: string | none = hdr.filename !is none
				? posix.relpath(hdr.filename, posix.headof(filename)).replace(posix.FS_SEP, "/")
				: none;
			if (relativeIncludePath !is none)
				relativeIncludePath = f'"{relativeIncludePath}"';
			local missingIncludeString: string;
			if (relativeIncludePath is none) {
				missingIncludeString = systemIncludeString;
			} else if (systemIncludeString is none) {
				missingIncludeString = relativeIncludePath;
			} else {
				switch (config.missingIncludeFormat) {
				case "shortest":
					missingIncludeString = {systemIncludeString, relativeIncludePath} < ...;
					break;
				case "shortestButNoUpRefs":
					missingIncludeString = !relativeIncludePath.startswith("../")
						? ({systemIncludeString, relativeIncludePath} < ...)
						: systemIncludeString;
					break;
				case "relative":
					missingIncludeString = relativeIncludePath;
					break;
				case "system":
					missingIncludeString = systemIncludeString;
					break;
				case "relativeIfNoUpRefs":
					missingIncludeString = relativeIncludePath.startswith("../")
						? systemIncludeString
						: relativeIncludePath;
					break;
				default:
					throw Error(f"Bad value for 'missingIncludeFormat': {repr config.missingIncludeFormat}");
				}
			}
			local comment: string | none = none;
			if (!hdr.noIncludeComments) {
				keywords = HashSet(keywords);
				hdr.simplifyKeywordUseList(keywords);
				comment = ", ".join(keywords.sorted(
					functools.predcmp2key(string.vercompare)
				));
			}
			local preferredIncludeGroup: SrcIncludeGroup | none = none;
			local includePriority: int | none = none;
			for (local grp: includeGroups) {
				if (isFormattingDisabledAt(grp.groupStartOffset))
					continue;
				if (includePriority is none)
					includePriority = clangFormatSpecs.getIncludePriorty(missingIncludeString);
				if (grp.containsIncludePriority(clangFormatSpecs, includePriority)) {
					preferredIncludeGroup = grp;
					break;
				}
				if (preferredIncludeGroup is none)
					preferredIncludeGroup = grp;
			}
			local commentStr = comment is none ? "" : f" /* {comment} */";
			if (preferredIncludeGroup is none) {
				printStderr(f"{filename}: Cannot automatically add missing include: #include {
					missingIncludeString}{commentStr}");
			} else {
				preferredIncludeGroup.addInclude(missingIncludeString, comment);
				printStderr(f"{filename}: Adding missing include: #include {
					missingIncludeString}{commentStr}");
			}
		}

		/* Re-format groups */
		for (local grp: includeGroups) {
			if (isFormattingDisabledAt(grp.groupStartOffset))
				continue;
			local reformattedBytes = grp.reformat(clangFormatSpecs);
			if (reformattedBytes !is none) {
				if (overwrite(
						grp.groupStartOffset,
						grp.groupEndOffset - grp.groupStartOffset,
						reformattedBytes
				)) {
					local d = lc(grp.groupStartOffset);
					printStderr(f"{filename}({d[0]}, {d[1]}): Re-formatted #include group");
				}
			}
		}

		if (dataChanged) {
			with (local fp = File.open(filename, "wb"))
				fp.write(data);
		}
	}

	public dump() {
		print(filename, ":");
		if (includes) {
			print("	includes:");
			for (local name: includes.keys.sorted()) {
				local info: SrcIncludeInfo = includes[name];
				print("		- ", name, ":");
				print("			includeStringOffset:    ", repr lc(info.includeStringOffset));
				print("			includeStringEndOffset: ", repr lc(info.includeStringEndOffset));
				if (info.commentStartOffset !is none)
					print("			commentStartOffset:     ", repr lc(info.commentStartOffset));
				if (info.commentEndOffset !is none)
					print("			commentEndOffset:       ", repr lc(info.commentEndOffset));
				if (info.comment !is none)
					print("			comment:                ", info.comment);
			}
		}
		if (keywords) {
			print("	keywords:");
			local longestKeywordLen = keywords.each.length > ...;
			for (local k: keywords.sorted()) {
				print("		- ", k),;
				if (k in selfProvidedKeyword) {
					print(" " * (longestKeywordLen - #k), " !self"),;
				}
				print;
			}
		}
		if (noFormatRegions) {
			print("	noFormatRegions:");
			for (local start, end: noFormatRegions)
				print("		- ", repr lc(start), " ... ", repr lc(end));
		}
	}
}


@@Parse a source file, determining symbols used, and includes present
function loadSrcFileInfo(filename: string): SrcFileInfo {
	filename = posix.resolvepath(posix.abspath(filename));
	local data: Bytes;
	with (local fp = File.open(filename, "rb"))
		data = fp.readall();
#if 1
	local parser = HeaderParser(
		data:            data,
		end:             #data,
		header:          Header(filename: filename),
		filename:        filename,
		noFormatRegions: List(),
		allKeywords:     HashSet(),
		allIncludes:     Dict(),
	).parseAll();

	local selfProvidedKeyword: {string...} = parser.allPotentiallyExportedKeywords;
	local allKeywords: {string...} = parser.allKeywords;
	selfProvidedKeyword.insertall(parser.header.exports);
	allKeywords.insertall(selfProvidedKeyword);
	return SrcFileInfo(
		filename:            filename,
		includes:            parser.allIncludes,
		keywords:            allKeywords,
		selfProvidedKeyword: selfProvidedKeyword,
		data:                data,
		noFormatRegions:     parser.noFormatRegions,
	);
#else
	local i = 0, len = #data;
	local includes: {string: SrcIncludeInfo} = Dict();
	local keywords: {string...} = HashSet();
	local noFormatRegions: {(int, int)...} = List();
	local currentNoFormatRegionStart: int | none = none;
	while (i < len) {
		if (data.isspace(i)) {
			++i;
			continue;
		} else if (data.startswith("//", i)) {
			i += 2;
seek_eol:
			i = data.find("\n", i);
			if (i < 0)
				break;
			++i;
		} else if (data.startswith("/*", i)) {
			if (data.startswith("/* clang-format off */", i)) {
				currentNoFormatRegionStart = i;
			} else if (data.startswith("/* clang-format on */", i)) {
				if (currentNoFormatRegionStart !is none) {
					noFormatRegions.append((currentNoFormatRegionStart, i));
					currentNoFormatRegionStart = none;
				}
			}
			i = data.find("*/", i + 2);
			if (i < 0)
				break;
			i += 2;
		} else if (data.startswith("#", i)) {
			local sol = data.rfind("\n", 0, i) + 1;
			if ((sol >= i) || data.isspace(sol, i)) {
				do {
					++i;
				} while (i < len && data.isspace(i));
				if (data.startswith("include ", i)) {
					i += #"include ";
					while (i < len && data.isspace(i))
						++i;
					local includeStart = i;
					if (data.startswith('"', i)) {
						i = data.find('"', i + 1);
						if (i < 0)
							break;
					} else if (data.startswith('<', i)) {
						i = data.find('>', i + 1);
						if (i < 0)
							break;
					} else {
						goto seek_eol;
					}
					++i;
					local includeEnd = i;
					local includeString = data[includeStart:includeEnd].decode("utf-8");
					while (i < len && data.isspacexlf(i))
						++i;
					local commentStartOffset: int | none = none;
					local commentEndOffset: int | none = none;
					if (data.startswith("/*", i)) {
						i += 2;
						commentStartOffset = i;
						i = data.find("*/", i);
						if (i < 0)
							break;
						commentEndOffset = i;
						i += 2;
					} else if (data.startswith("//", i)) {
						i += 2;
						commentStartOffset = i;
						i = data.find("\n", i);
						if (i < 0)
							break;
						commentEndOffset = i;
						i += 1;
					}
					local comment = none;
					if (commentStartOffset !is none) {
						while (commentStartOffset < commentEndOffset && data.isspace(commentStartOffset))
							++commentStartOffset;
						while (commentEndOffset > commentStartOffset && data.isspace(commentEndOffset - 1))
							--commentEndOffset;
						comment = data[commentStartOffset:commentEndOffset];
					}
					if (includeString !in includes) {
						includes[includeString] = SrcIncludeInfo(
							include: includeString,
							includeStringOffset: includeStart,
							includeStringEndOffset: includeEnd,
							commentStartOffset: commentStartOffset,
							commentEndOffset: commentEndOffset,
							comment: comment,
						);
					}
					goto seek_eol;
				}
			}
			++i;
		} else if (data.issymstrt(i)) {
			local kwdStart = i;
			do {
				++i;
			} while (i < len && data.issymcont(i));
			/* XXX: in "struct foo;", "foo" must not be considered a dependency.
			 *      so-long as no actual instance of "foo" is created, and none
			 *      of "foo"'s fields are accessed:
			 * >> struct foo;
			 * >> extern void bar(struct foo *x);
			 *    ^ This code **DOESN'T** need to depend on "foo"
			 * >> struct foo;
			 * >> extern void bar(struct foo x);
			 *    ^ This code **DOES** need to depend on "foo"
			 */
			keywords.insert(data[kwdStart:i].decode("utf-8"));
		} else {
			++i;
		}
	}

	return SrcFileInfo(
		filename: filename,
		includes: includes,
		keywords: keywords.frozen,
		data: data,
		noFormatRegions: noFormatRegions,
	);
#endif
}



@@Main FixIncludes controller
class FixIncludes {
	this = default;

	@@Headers mapped by their system include names
	public member headersByInclude: {string: Header} = Dict();

	@@Headers mapped by their (normalized) filesystem names
	public member headersByFilename: {string: Header} = Dict();

	@@Exports mapped to the sets of headers that must be
	@@included in order to get those exports
	public member headersByExport: {string: Set with {Header...}} = Dict();

	public function getHeaderByInclude(include: string): Header | none {
		local result = headersByInclude.get(include);
		if (result is none)
			result = DEFAULT_HEADERS_BY_INCLUDE.get(include);
		return result;
	}

	public function getHeaderByFilename(filename: string): Header | none {
		return headersByFilename.get(filename);
	}

	@@Return groups of headers which (when combined) make @keyword available
	@@Headers marked as `/*!fixincludes discourage_include*/` and that are
	@@always included by other headers are replace with those other headers
	@@in the returned sequence.
	public function getHeaderByExport(keyword: string): Set with {Header...} {
		return headersByExport.get(keyword, {});
	}

	@@Return the header specified by @dep and included by @base
	public function getDependentHeader(base: Header | string, dep: DependentFile): Header | none {
		if (dep.filename !is none) {
			local depFilename = posix.resolvepath(
				posix.joinpath(posix.headof(base is string ? base : base.filename), dep.filename));
			local result = getHeaderByFilename(depFilename);
			if (result !is none)
				return result;
		}
		if (dep.include !is none)
			return getHeaderByInclude(dep.include);
		return none;
	}

	private doLoadHeaderInPath(
			relPath: string, absPath: string,
			pool: ThreadPool, fileTasks: {string: Task},
			exclude: {string...}) {
		for (local ent: posix.opendir(absPath)) {
			local name = ent.d_name;
			local relName = f'{relPath}/{name}'.lstrip("/");
			local absName = posix.joinpath(absPath, name);
			if (absName in exclude)
				continue;
			if (ent.d_type == posix.DT_REG) {
				if (name.endswith(".h")) {
					local existingTask: Task | none = fileTasks.get(absName);
					if (existingTask !is none) {
						local hdr = existingTask.waitfor();
						hdr.includes.insert(relName);
						headersByInclude[relName] = hdr;
					} else {
						fileTasks[absName] = pool.run(() -> {
							printStderr(f"Scan header {repr absName}...");
							local hdr = loadHeader(absName);
							hdr.includes.insert(relName);
							headersByFilename[absName] = hdr;
							headersByInclude[relName] = hdr;
							printStderr(f"Done header {repr absName}");
							return hdr;
						});
					}
				}
			} else if (ent.d_type == posix.DT_DIR) {
				doLoadHeaderInPath(relName, absName, pool, fileTasks, exclude);
			}
		}
	}

	@@Load files from the given set to system include paths
	public addIncludePaths(include: {string...}, exclude: {string...} = ()): FixIncludes {
		local pool = ThreadPool();
		local fileTasks: {string: Task} = Dict();
		exclude = Set.frozen(for (local xp: exclude) posix.resolvepath(posix.abspath(xp)));
		for (local path: include.sorted()) {
			path = posix.resolvepath(posix.abspath(path));
			doLoadHeaderInPath("", path, pool, fileTasks, exclude);
		}
		pool.waitfor();
		for (local task: fileTasks.values)
			task.waitfor();
		return this;
	}



	@@Recursively resolve `#include ... /*!always*/` directives by
	@@adding the always-included header of one header to another
	@@header that always includes the first. Then, add the exports
	@@to of all always-included headers to headers that always include
	@@those other headers.
	public addImplicitIncludesAndExports() {
		/* Transfer implicit always-includes */
		local foundNestedRecursiveIncludes;
		do {
			foundNestedRecursiveIncludes = false;
			for (local hdr: headersByFilename.values) {
				local more: {DependentFile...} = HashSet();
				for (local always: hdr.alwaysIncludes) {
					local dep: Header | none = getDependentHeader(hdr, always);
					if (dep !is none) {
						for (local a: dep.alwaysIncludes) {
							if (a.filename !is none) {
								local srcDir = posix.headof(dep.filename);
								local dstDir = posix.headof(hdr.filename);
								local newFilename = a.filename;
								if (!posix.isabs(newFilename))
									newFilename = posix.abspath(newFilename, srcDir);
								newFilename = posix.relpath(newFilename, dstDir);
								if (posix.FS_SEP != "/")
									newFilename = newFilename.replace(posix.FS_SEP, "/");
								a = DependentFile(filename: newFilename, include: a.include);
							}
							if (a !in hdr.alwaysIncludes)
								more.insert(a);
						}
					}
				}
				if (more) {
					hdr.alwaysIncludes.insertall(more);
					foundNestedRecursiveIncludes = true;
				}
			}
		} while (foundNestedRecursiveIncludes);

		/* Populate the "alwaysIncludedBy" attributes of headers */
		for (local hdr: headersByFilename.values) {
			for (local always: hdr.alwaysIncludes) {
				local dep: Header | none = getDependentHeader(hdr, always);
				if (dep !is none)
					dep.alwaysIncludedBy.insert(hdr.filename);
			}
		}

		/* Add implicit always-exports */
		local foundNestedRecursiveExports;
		do {
			foundNestedRecursiveExports = false;
			for (local hdr: headersByFilename.values) {
				local more: {string...} = HashSet();
				for (local always: hdr.alwaysIncludes) {
					local dep: Header | none = getDependentHeader(hdr, always);
					if (dep !is none) {
						for (local a: dep.exports) {
							if (a !in hdr.exports)
								more.insert(a);
						}
					}
				}
				if (more) {
					hdr.exports.insertall(more);
					hdr.exportsFromAlwaysIncludes.insertall(more);
					foundNestedRecursiveExports = true;
				}
			}
		} while (foundNestedRecursiveExports);
	}

	@@Populate @headersByExport
	public buildHeadersByExport() {
		local headersByExport: {string: Set with {Header...}} = Dict();
		for (local hdr: headersByFilename.values) {
			if (hdr.alwaysIncludedBy && hdr.discourageInclude) {
				/* Ignore these types of headers (another
				 * header that should be included instead) */
				continue;
			}
			local exportsAfterExtraIncludes: {string: Set with Set with DependentFile}
				= hdr.exportsAfterExtraIncludes;
			for (local export: hdr.exports) {
				local extraIncludesCombinations: Set with Set with DependentFile
					= exportsAfterExtraIncludes.get(export, Set());
				local exportHeaders: Set with {Header...} | none = headersByExport.get(export);
				if (exportHeaders is none)
					headersByExport[export] = exportHeaders = HashSet();
				if (!extraIncludesCombinations) {
					/* Likely case: no extra includes necessary */
					exportHeaders.insert({ hdr });
				} else {
					/* Complicated case: more headers are needed */
					for (local dependentIncludes: extraIncludesCombinations) {
						local neededHeaders: {Header...} = List({ hdr });
						for (local dependentInclude: dependentIncludes) {
							local depHdr: Header | none = getDependentHeader(hdr, dependentInclude);
							if (depHdr is none)
								depHdr = dependentInclude.asDummyHeader;
							neededHeaders.append(depHdr);
						}
						neededHeaders.sort(e -> e.filename ?? "");
						exportHeaders.insert(neededHeaders);
					}
				}
			}
		}
		for (local inclusionSets: headersByExport.values) {
			assert inclusionSets;
			if (#inclusionSets >= 2) {
				/* Check if we can simplify the set:
				 *
				 */
			}
		}
		this.headersByExport = headersByExport;
	}

	@@Helper method that does all calls necessary once
	@@all calls to @addIncludePaths have been placed:
	@@ - @addImplicitIncludesAndExports
	@@ - @buildHeadersByExport
	public finishSetup(): FixIncludes {
		addImplicitIncludesAndExports();
		buildHeadersByExport();
		return this;
	}

	@@Print a dump of @headersByExport, which essentially dumps info
	@@describing which keyword is exported by which set of headers.
	public dumpExports(): FixIncludes {
		local longestKeywordLength = headersByExport.keys.each.length > ...;
		for (local kwd: headersByExport.keys.sorted()) {
			local hdrCombinations: Set with {Header...} = headersByExport[kwd];
			print(kwd.ljust(longestKeywordLength), " : ", f"\{ {", ".join(hdrCombinations.map(
				(hdrs: {Header...}) -> f"\{ {", ".join(hdrs.map(operator str))} \}"
			))} \}");
		}
		return this;
	}

	@@Print a dump of loaded headers, and their configurations (useful to
	@@see what was actually loaded, and debug weird behavior when includes
	@@appear to be linked incorrectly)
	public dumpHeaders(): FixIncludes {
		for (local filename: headersByFilename.keys.sorted())
			headersByFilename[filename].dump();
		return this;
	}


	@@Fix `#include`-s in @filename based on information loaded into @this @FixIncludes
	public fixFile(filename: string, config: FixConfig | none = none): FixIncludes {
		if (config is none)
			config = FixConfig();
		loadSrcFileInfo(filename).fix(this, config);
		return this;
	}


	private doFixPath(
		absPath: string,
		exclude: {string...},
		pool: ThreadPool,
		fixTasks: {string: Task},
		config: FixConfig,
	) {
		for (local ent: posix.opendir(absPath)) {
			local name = ent.d_name;
			local absName = posix.joinpath(absPath, name);
			if (absName in exclude)
				continue;
			if (ent.d_type == posix.DT_REG) {
				if (name.rpartition(".").last in ["c", "h", "inl"]) {
					if (absName !in fixTasks) {
						fixTasks[absName] = pool.run(() -> {
							printStderr(f"Checking {repr absName}...");
							fixFile(absName, config);
						});
					}
				}
			} else if (ent.d_type == posix.DT_DIR) {
				doFixPath(absName, exclude, pool, fixTasks, config);
			}
		}
	}

	@@Fix all files in @include, but exclude files from @exclude
	public fixPaths(
		include: {string...},
		exclude: {string...},
		config: FixConfig | none = none,
	): FixIncludes {
		if (config is none)
			config = FixConfig();
		local pool = ThreadPool();
		local fixTasks: {string: Task} = Dict();
		exclude = Set.frozen(for (local xp: exclude) posix.resolvepath(posix.abspath(xp)));
		for (local path: include.sorted()) {
			path = posix.resolvepath(posix.abspath(path));
			doFixPath(path, exclude, pool, fixTasks, config);
		}
		pool.waitfor();
		for (local task: fixTasks.values)
			task.waitfor();
		return this;
	}
}


/* TODO: Combination of "/util/scripts/fixincludes.dee" and KOS's "/misc/build/editorconfig.dee"
 * Should be a fully-featured program that can be used to:
 * - Find missing #include-s
 * - Generate a ".editorconfig" suitable for use with visual studio
 *   (TODO: This part still has to be implemented)
 */

